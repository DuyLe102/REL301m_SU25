{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK-kqW_zQp6s",
        "outputId": "fe126469-165d-4372-f363-073fdf6561a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-place: 113 iterations\n",
            "Synchronous: 172 iterations\n"
          ]
        }
      ],
      "source": [
        "#######################################################################\n",
        "# Copyright (C)                                                       #\n",
        "# 2016-2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)             #\n",
        "# 2016 Kenta Shimada(hyperkentakun@gmail.com)                         #\n",
        "# Permission given to modify the code as long as you keep this        #\n",
        "# declaration at the top                                              #\n",
        "#######################################################################\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.table import Table\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "WORLD_SIZE = 4\n",
        "# left, up, right, down\n",
        "ACTIONS = [np.array([0, -1]),\n",
        "           np.array([-1, 0]),\n",
        "           np.array([0, 1]),\n",
        "           np.array([1, 0])]\n",
        "ACTION_PROB = 0.25\n",
        "\n",
        "\n",
        "def is_terminal(state):\n",
        "    x, y = state\n",
        "    return (x == 0 and y == 0) or (x == WORLD_SIZE - 1 and y == WORLD_SIZE - 1)\n",
        "\n",
        "\n",
        "def step(state, action):\n",
        "    if is_terminal(state):\n",
        "        return state, 0\n",
        "\n",
        "    next_state = (np.array(state) + action).tolist()\n",
        "    x, y = next_state\n",
        "\n",
        "    if x < 0 or x >= WORLD_SIZE or y < 0 or y >= WORLD_SIZE:\n",
        "        next_state = state\n",
        "\n",
        "    reward = -1\n",
        "    return next_state, reward\n",
        "\n",
        "\n",
        "def draw_image(image):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_axis_off()\n",
        "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
        "\n",
        "    nrows, ncols = image.shape\n",
        "    width, height = 1.0 / ncols, 1.0 / nrows\n",
        "\n",
        "    # Add cells\n",
        "    for (i, j), val in np.ndenumerate(image):\n",
        "        tb.add_cell(i, j, width, height, text=val,\n",
        "                    loc='center', facecolor='white')\n",
        "\n",
        "        # Row and column labels...\n",
        "    for i in range(len(image)):\n",
        "        tb.add_cell(i, -1, width, height, text=i+1, loc='right',\n",
        "                    edgecolor='none', facecolor='none')\n",
        "        tb.add_cell(-1, i, width, height/2, text=i+1, loc='center',\n",
        "                    edgecolor='none', facecolor='none')\n",
        "    ax.add_table(tb)\n",
        "\n",
        "\n",
        "def compute_state_value(in_place=True, discount=1.0):\n",
        "    new_state_values = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
        "    iteration = 0\n",
        "    while True:\n",
        "        if in_place:\n",
        "            state_values = new_state_values\n",
        "        else:\n",
        "            state_values = new_state_values.copy()\n",
        "        old_state_values = state_values.copy()\n",
        "\n",
        "        for i in range(WORLD_SIZE):\n",
        "            for j in range(WORLD_SIZE):\n",
        "                value = 0\n",
        "                for action in ACTIONS:\n",
        "                    (next_i, next_j), reward = step([i, j], action)\n",
        "                    value += ACTION_PROB * (reward + discount * state_values[next_i, next_j])\n",
        "                new_state_values[i, j] = value\n",
        "\n",
        "        max_delta_value = abs(old_state_values - new_state_values).max()\n",
        "        if max_delta_value < 1e-4:\n",
        "            break\n",
        "\n",
        "        iteration += 1\n",
        "\n",
        "    return new_state_values, iteration\n",
        "\n",
        "\n",
        "def figure_4_1():\n",
        "    # While the author suggests using in-place iterative policy evaluation,\n",
        "    # Figure 4.1 actually uses out-of-place version.\n",
        "    _, asycn_iteration = compute_state_value(in_place=True)\n",
        "    values, sync_iteration = compute_state_value(in_place=False)\n",
        "    draw_image(np.round(values, decimals=2))\n",
        "    print('In-place: {} iterations'.format(asycn_iteration))\n",
        "    print('Synchronous: {} iterations'.format(sync_iteration))\n",
        "\n",
        "    plt.savefig('figure_4_1.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    figure_4_1()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.table import Table\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "WORLD_HEIGHT = 5  # Tăng chiều cao lên 5 để thêm state 15\n",
        "WORLD_WIDTH = 4\n",
        "ACTIONS = [np.array([0, -1]),  # left\n",
        "           np.array([-1, 0]),  # up\n",
        "           np.array([0, 1]),   # right\n",
        "           np.array([1, 0])]   # down\n",
        "ACTION_PROB = 0.25\n",
        "\n",
        "# State 15 nằm ở vị trí (4,1)\n",
        "# Terminal states: (0,0) và (3,3)\n",
        "def is_terminal(state):\n",
        "    x, y = state\n",
        "    return (x == 0 and y == 0) or (x == 3 and y == 3)\n",
        "\n",
        "# Hàm step mở rộng cho Bài tập 4.2\n",
        "def step(state, action, scenario='a'):\n",
        "    if is_terminal(state):\n",
        "        return state, 0\n",
        "\n",
        "    x, y = state\n",
        "\n",
        "    # Xử lý đặc biệt cho state 13 (3,1)\n",
        "    if scenario == 'b' and (x, y) == (3, 1) and np.array_equal(action, ACTIONS[3]):  # down\n",
        "        return (4, 1), -1\n",
        "\n",
        "    # Xử lý đặc biệt cho state 15 (4,1)\n",
        "    if (x, y) == (4, 1):\n",
        "        if np.array_equal(action, ACTIONS[0]):  # left\n",
        "            next_state = (3, 0)\n",
        "        elif np.array_equal(action, ACTIONS[1]):  # up\n",
        "            next_state = (3, 1)\n",
        "        elif np.array_equal(action, ACTIONS[2]):  # right\n",
        "            next_state = (3, 2)\n",
        "        elif np.array_equal(action, ACTIONS[3]):  # down\n",
        "            next_state = (4, 1)\n",
        "        return next_state, -1\n",
        "\n",
        "    # Xử lý các state khác\n",
        "    next_state = (np.array(state) + action).tolist()\n",
        "    x, y = next_state\n",
        "\n",
        "    # Kiểm tra biên\n",
        "    if x < 0 or x >= WORLD_HEIGHT or y < 0 or y >= WORLD_WIDTH:\n",
        "        next_state = state\n",
        "\n",
        "    reward = -1\n",
        "    return next_state, reward\n",
        "\n",
        "def draw_image(image):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_axis_off()\n",
        "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
        "\n",
        "    nrows, ncols = image.shape\n",
        "    width, height = 1.0 / ncols, 1.0 / nrows\n",
        "\n",
        "    # Add cells\n",
        "    for (i, j), val in np.ndenumerate(image):\n",
        "        tb.add_cell(i, j, width, height, text=val,\n",
        "                    loc='center', facecolor='white')\n",
        "\n",
        "    # Row and column labels...\n",
        "    for i in range(len(image)):\n",
        "        tb.add_cell(i, -1, width, height, text=i+1, loc='right',\n",
        "                    edgecolor='none', facecolor='none')\n",
        "        tb.add_cell(-1, i, width, height/2, text=i+1, loc='center',\n",
        "                    edgecolor='none', facecolor='none')\n",
        "    ax.add_table(tb)\n",
        "\n",
        "def compute_state_value(scenario='a', discount=1.0):\n",
        "    state_values = np.zeros((WORLD_HEIGHT, WORLD_WIDTH))\n",
        "    iteration = 0\n",
        "    while True:\n",
        "        new_state_values = state_values.copy()\n",
        "        delta = 0\n",
        "\n",
        "        for i in range(WORLD_HEIGHT):\n",
        "            for j in range(WORLD_WIDTH):\n",
        "                if is_terminal((i, j)):\n",
        "                    continue\n",
        "\n",
        "                value = 0\n",
        "                for action in ACTIONS:\n",
        "                    (next_i, next_j), reward = step([i, j], action, scenario)\n",
        "                    value += ACTION_PROB * (reward + discount * state_values[next_i, next_j])\n",
        "\n",
        "                new_state_values[i, j] = value\n",
        "                delta = max(delta, abs(value - state_values[i, j]))\n",
        "\n",
        "        state_values = new_state_values\n",
        "        if delta < 1e-4:\n",
        "            break\n",
        "\n",
        "        iteration += 1\n",
        "\n",
        "    return state_values, iteration\n",
        "\n",
        "def exercise_4_2():\n",
        "    # Phần (a): Không thay đổi dynamics của state 13\n",
        "    print(\"Part (a): Original dynamics unchanged for state 13\")\n",
        "    values_a, iter_a = compute_state_value(scenario='a')\n",
        "    print(f\"Converged in {iter_a} iterations\")\n",
        "    print(f\"v_π(15) = {values_a[4, 1]:.2f}\\n\")\n",
        "\n",
        "    # Phần (b): Thay đổi dynamics của state 13\n",
        "    print(\"Part (b): Changed dynamics for state 13\")\n",
        "    values_b, iter_b = compute_state_value(scenario='b')\n",
        "    print(f\"Converged in {iter_b} iterations\")\n",
        "    print(f\"v_π(15) = {values_b[4, 1]:.2f}\")\n",
        "\n",
        "    # Vẽ kết quả cho phần (b)\n",
        "    draw_image(np.round(values_b, decimals=2))\n",
        "    plt.savefig('gridworld_4_2.png')\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    exercise_4_2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCGMF-9kWEGG",
        "outputId": "cc6e9091-229a-47bf-d4aa-f36cf15f2641"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part (a): Original dynamics unchanged for state 13\n",
            "Converged in 183 iterations\n",
            "v_π(15) = -21.45\n",
            "\n",
            "Part (b): Changed dynamics for state 13\n",
            "Converged in 183 iterations\n",
            "v_π(15) = -21.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqu3K295awOx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}